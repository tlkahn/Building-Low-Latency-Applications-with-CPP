* Processing Market Data and Sending Orders to the Exchange in C++

In this chapter, we will build the client's C++ system that receives and processes market data updates from the trading exchange. We will also have to deal with creating and reading from UDP sockets, dealing with packet losses, etc. We will discuss the design of an order book on the client side to track the order book maintained at the trading exchange. We will also implement the C++ components needed to establish and maintain TCP connections to the trading exchange. We will also implement functionality to send orders to the exchange from the strategies and receive and process order responses.

In this chapter, we will cover the following topics:

- Subscribing to market data and decoding the market data protocol
- Building order books from market data
- Connecting to the exchange, sending order requests, and receiving responses

* Technical requirements

All the code for this book can be found in the GitHub repository for this book at [[https://github.com/PacktPublishing/Building-Low-Latency-Applications-with-CPP]]. The source for this chapter is in the *Chapter 8* directory in the repository.

You must read and understand the design of the electronic trading ecosystem presented in the chapter /Designing Our Trading Ecosystem/. The components we build in this chapter will interact with the electronic trading exchange application we built in the chapter /Communicating With Market Participants/, so we assume you are familiar with that. The limit order book we will build in the client application's trade engine component is almost identical to the order book we built inside the matching engine in the chapter /Building the C++ Matching Engine/ within the /Building the order book and matching orders/ section. So, we assume the reader is very familiar with that chapter and the code we discussed there as we will make references to that in this chapter. As before, we will use the building blocks we built in the /Building the C++ Building Blocks for Low Latency/ /Applications/ chapter.

The specifications of the environment in which the source code for this book was developed are shown in the following bullet list. We present the details of this environment since all the C++ code presented in this book is not necessarily portable and might require some minor changes to work in your environment:

- OS -- *Linux 5.19.0-41-generic #42~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr 18 17:40:00 UTC 2 x86_64 x86_64* *x86_64 GNU/Linux*
- GCC -- *g++ (Ubuntu* *11.3.0-1ubuntu1~22.04.1) 11.3.0*
- CMAKE -- *cmake* *version 3.23.2*
- NINJA -- *1.10.2*

* Subscribing to market data and decoding the market data protocol

The first component we need to build inside the market participants' trading system is the market data consumer. This component is responsible for subscribing to the multicast stream of public market data updates published by the trading exchange. It needs to decode the market data stream generated by the exchange from the public *MDPMarketUpdate* format we discussed earlier. Because of the choice of the *Simple Binary Encoding* (*SBE*) protocol, the decoding step is straightforward in our application and does not involve any complicated stream decoding logic. Another important responsibility of this component is detecting packet drops on the incremental market data stream and providing mechanisms to recover and synchronize with the market data stream again. This mechanism is also required for trading systems that subscribe to the market data stream after there is a non-empty order book, i.e. after the trading exchange is already open and accepting client orders. Also, this will be required if the trading application needs to be restarted in the middle of the day.

We present a detailed diagram of the market data consumer component we have seen before. As shown in /Figure 8//.1/, it consumes multicast data containing market data updates from the incremental and optionally the snapshot stream. After checking for sequence numbers on the market data updates and potentially needing to synchronize between the snapshot and the incremental streams, it decodes the market data updates. It then generates a stream of decoded and in-order market data updates for the trading engine to consume and publishes them over a lock-free queue:

[[file:///Users/toeinriver/Documents/org/web/WebImg/b4243cbf12e21c9652ebee7b45eceae7c88e891ddf16c80d5af0109bb0df2598.jpg]]

Figure 8.1 -- An overview of the market data consumer component and its sub-components

Before we jump into the design and implementation of the market data consumer component, we would like to mention that the source code for this component can be found in the *Chapter8/trading/market_data/market_data_consumer.h* source file and the *Chapter8/trading/market_data/market_data_consumer.cpp* source file. Next, let us get started by first defining the internal data members that the market data consumer component will need.

** Defining the data members in the market data consumer

The *MarketDataConsumer* class we are going to build will need a couple of important data members as shown in the following bullet list:

- First, it needs a lock-free *incoming_md_updates_* queue instance of the *Exchange::MEMarketUpdateLFQueue* type, which we defined before. This is meant to be used by *MarketDataConsumer* to publish the *MEMarketUpdate* messages to the trading engine component.
- We will maintain a *next_exp_inc_seq_num_* variable of the *size_t* type, which will be used to make sure that we process updates from the incremental market data stream in the correct order and detect packet drops on the incremental market data stream.
- We will have two multicast subscriber sockets -- *incremental_mcast_socket_* and *snapshot_mcast_socket_* of the *Common::McastSocket* types. These correspond to the sockets we will use to subscribe to and consume multicast data from the incremental and the snapshot multicast streams, respectively.

To perform the recovery/synchronization from the snapshot market data stream when needed, we will need to maintain a couple of extra data members, as shown in the following bullet list:

- First, we will store an *in_recovery_* boolean flag to signify if *MarketDataConsumer* detected a packet drop and is currently trying to recover using the snapshot and incremental market data streams.
- Since we will join and leave the snapshot multicast stream as needed, we will have the multicast stream and network interface information in the *iface_* variable, the *snapshot_ip_ variable*, and the *snapshot_port_* variable. These represent the network interface to use, the IP address, and the port of the snapshot multicast stream.
- Finally, we define a type to queue up messages and order them by their corresponding sequence number. We will use the *Standard Template Library* (*STL*) *std::map* type here and paramaterize it to use keys of the *size_t* type (to represent the sequence number of the update), hold objects of *Exchange::MEMarketUpdate*, and call this type *QueuedMarketUpdates* using *typedef*. We chose the *std::map* type here since it is easier to iterate over sorted keys compared to, say, *std::unordered _map*. Note that *std::map* is not efficient for a wide range of reasons -- the internal data structure is *Red Black Tree*, which has an asymptotic insertion performance of *O(log(N))* and causes dynamic memory allocations, etc. However, we make an exception in this case because snapshot recovery is expected to be extremely rare, and when the *MarketDataConsumer* class is recovering from the snapshot stream, trading is generally paused inside the client's trading application since it does not have an accurate view of the state of the order book. Additionally, the snapshot stream is delayed and throttled from the exchange's side, so the snapshot synchronization process itself is not required to be low latency.
- We create two instances of this *QueuedMarketUpdates* type -- *snapshot_queued_msgs_* and *incremental_queued_msgs_*, one to queue up *MEMarketUpdate* messages from the snapshot stream and one to queue up *MEMarketUpdate* messages from the incremental stream.
- The *MarketDataConsumer* class is also a different thread of execution, so similar to the classes we have seen before, it has a *run_* boolean flag to control the execution of the thread and it is marked *volatile* since it is accessed from different threads:

#+begin_src cpp
#pragma once
#include <functional>
#include <map>
#include "common/thread_utils.h"
#include "common/lf_queue.h"
#include "common/macros.h"
#include "common/mcast_socket.h"
#include "exchange/market_data/market_update.h"
namespace Trading {
class MarketDataConsumer {
private:
    size_t next_exp_inc_seq_num_ = 1;
    Exchange::MEMarketUpdateLFQueue *incoming_md_updates_ =
      nullptr;
    volatile bool run_ = false;
    std::string time_str_;
    Logger logger_;
    Common::McastSocket incremental_mcast_socket_,
      snapshot_mcast_socket_;
    bool in_recovery_ = false;
    const std::string iface_, snapshot_ip_;
    const int snapshot_port_;
    typedef std::map<size_t, Exchange::MEMarketUpdate>
      QueuedMarketUpdates;
    QueuedMarketUpdates snapshot_queued_msgs_,
      incremental_queued_msgs_;
};
}
#+end_src

We will initialize the *MarketDataConsumer* class and these data members in the next section.

** Initializing the market data consumer

The constructor for the *MarketDataConsumer* class accepts the following arguments:

- A *client_id* argument of the *Common::ClientId* type, which in this case is used purely to create a unique log filename to be used to initialize the *Logger logger_* component in this class.
- It also expects a pointer to a *MEMarketUpdateLFQueue* lock-free queue object called *market_updates*, where it will publish decoded and in-order market updates.
- It expects the network interface name in the *iface* argument and the addresses of the snapshot and incremental market data streams. These will be passed in the *snapshot_ip* argument, the *snapshot_port* argument, the *incremental_ip* argument, and the *incremental_port* argument:

#+begin_src cpp
#include "market_data_consumer.h"
namespace Trading {
  MarketDataConsumer::MarketDataConsumer(Common::ClientId
    client_id, Exchange::MEMarketUpdateLFQueue
      *market_updates,
const std::string &iface,
const std::string &snapshot_ip, int snapshot_port,
const std::string &incremental_ip, int incremental_port)
      : incoming_md_updates_(market_updates), run_(false),
        logger_("trading_market_data_consumer_" + std::
          to_string(client_id) + ".log"),
        incremental_mcast_socket_(logger_),
          snapshot_mcast_socket_(logger_),
        iface_(iface), snapshot_ip_(snapshot_ip),
          snapshot_port_(snapshot_port) {
#+end_src

The constructor performs the following tasks:

- As we mentioned, the constructor creates a *Logger* instance for this class and uses that *logger_* object to initialize the *incremental_mcast_socket_* variable and the *snapshot_mcast_socket_* variable. It also initializes the *iface_*, *snapshot_ip_*, and *snapshot_port_* members from the arguments passed to it.
- Using the *recv_callback()* lambda method, it initializes the *recv_callback_* variable in the *incremental_mcast_socket_* variable and the *snapshot_mcast_socket_* variable. The lambda just forwards the callbacks to the *recvCallback()* member method in the *MarketDataConsumer* class, which we will see later. The key point here is that we expect the *MarketDataConsumer::recvCallback()* method to be called when there is data available on the incremental or the snapshot multicast sockets.
- The last thing the constructor does is fully initialize *incremental_mcast_socket_* by calling the *McastSocket::init()* method, which creates the actual socket internally. It also calls the *McastSocket::join()* method to subscribe to the multicast stream for this socket. Note that we do not do the same for *snapshot_mcast_socket_* yet. That is done on demand as packet drops or sequence gaps are detected:

#+begin_src cpp
    auto recv_callback = [this](auto socket) {
      recvCallback(socket);
    };
    incremental_mcast_socket_.recv_callback_ =
      recv_callback;
    ASSERT(incremental_mcast_socket_.init(incremental_ip,
      iface, incremental_port, /*is_listening*/ true) >= 0,
           "Unable to create incremental mcast socket.
             error:" + std::string(std::strerror(errno)));
    ASSERT(incremental_mcast_socket_.join(incremental_ip,
      iface, incremental_port),
           "Join failed on:" + std::to_string
              (incremental_mcast_socket_.fd_) + " error:" +
                 std::string(std::strerror(errno)));
    snapshot_mcast_socket_.recv_callback_ = recv_callback;
  }
#+end_src

We add a *start()* method like what we have seen for our other components on the side of the trading exchange. This sets the *run_* variable to be *true* and creates and launches a thread to execute the *MarketDataConsumer::run()* method, which we will build later:

#+begin_src cpp
    auto start() {
      run_ = true;
      ASSERT(Common::createAndStartThread(-1,
        "Trading/MarketDataConsumer", [this]() { run(); })
          != nullptr, "Failed to start MarketData
             thread.");
    }
#+end_src

The destructor for this class is straightforward and calls the *stop()* method, which simply sets the *run_* flag to *false* to end the execution of the *run()* method:

#+begin_src cpp
    ~MarketDataConsumer() {
      stop();
      using namespace std::literals::chrono_literals;
      std::this_thread::sleep_for(5s);
    }
    auto stop() -> void {
      run_ = false;
    }
#+end_src

Now that we have initialized the *MarketDataConsumer* class, we will first look at the main *run()* loop, which executes a loop of consuming multicast traffic from the exchange.

** Running the market data consumer main loop

The *run()* method is simple for our market data consumer component. It simply calls the *sendAndRecv()* method on the *incremental_mcast_socket_* socket and the *snapshot_mcast_socket_* object, which in our case, consumes any additional data received on the incremental or snapshot channels and dispatches the callbacks:

#+begin_src cpp
  auto MarketDataConsumer::run() noexcept -> void {
    logger_.log("%:% %() %\n", __FILE__, __LINE__,
      __FUNCTION__, Common::getCurrentTimeStr(&time_str_));
    while (run_) {
      incremental_mcast_socket_.sendAndRecv();
      snapshot_mcast_socket_.sendAndRecv();
    }
  }
#+end_src

The next section deals with the data available on the network sockets within the *recvCallback()* method that get dispatched from the previous logic.

** Processing market data updates and handling packet drops

This section implements important functionality responsible for processing market data updates received on the incremental and the snapshot streams. Market updates on the incremental stream are received during the entire runtime of the *MarketDataConsumer* component. However, data is received and processed from the snapshot stream only when a sequence number gap is detected on the incremental stream, which causes *MarketDataConsumer* to initialize *snapshot_mcast_socket_* and subscribe to the snapshot multicast stream. Remember that in the constructor of *MarketDataConsumer*, we intentionally did not fully initialize *snapshot_mcast_socket_* as we did with the *incremental_mcast_socket_*. The important thing to understand here is that data on the snapshot socket is only received when we are in recovery mode and not otherwise.

The first code block in the *recvCallback()* method determines if the data we are processing came from the incremental or snapshot stream by comparing the file descriptor of the socket on which it was received. In the extremely unlikely edge case that we received data on the snapshot socket but we are not in recovery, we simply log a warning, reset the socket receive buffer index, and return:

#+begin_src cpp
  auto MarketDataConsumer::recvCallback(McastSocket
    *socket) noexcept -> void {
    const auto is_snapshot = (socket->fd_ ==
      snapshot_mcast_socket_.fd_);
    if (UNLIKELY(is_snapshot && !in_recovery_)) {
      socket->next_rcv_valid_index_ = 0;
      logger_.log("%:% %() % WARN Not expecting snapshot
        messages.\n",
                  __FILE__, __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_));
      return;
    }
#+end_src

Otherwise, we proceed further and read *Exchange::MDPMarketUpdate* messages from the socket buffer using the same code that we have seen before. We go through the data contained in the *socket->rcv_buffer_* buffer and read it in chunks of size equal to the size of *Exchange::MDPMarketUpdate*. The goal here is to read as many full *MDPMarketUpdate* messages as possible until we have read them all from the buffer. We use *reinterpret_cast* to convert the data in the buffer to an object of the *Exchange::MDPMarketUpdate* type:

#+begin_src cpp
    if (socket->next_rcv_valid_index_ >= sizeof
      (Exchange::MDPMarketUpdate)) {
      size_t i = 0;
      for (; i + sizeof(Exchange::MDPMarketUpdate) <=
        socket->next_rcv_valid_index_; i +=
          sizeof(Exchange::MDPMarketUpdate)) {
        auto request = reinterpret_cast<const
          Exchange::MDPMarketUpdate *>(socket->rcv_buffer_
            + i);
        logger_.log("%:% %() % Received % socket len:%
          %\n", __FILE__, __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_),
                    (is_snapshot ? "snapshot" :
                       "incremental"), sizeof
                         (Exchange::MDPMarketUpdate),
                           request->toString());
#+end_src

For each *MDPMarketUpdate* message, we check the sequence number on the message we just read to see if there is a sequence number gap or not. We set the *in_recovery_* member flag to be *true* if we detect a sequence number gap or if we were already in recovery:

#+begin_src cpp
        const bool already_in_recovery = in_recovery_;
        in_recovery_ = (already_in_recovery || request->
          seq_num_ != next_exp_inc_seq_num_);
#+end_src

First, we will see the handling of the message if we are in recovery mode. In the next code block, we first check the *already_in_recovery_* flag to see if we were previously not in recovery and just started recovery due to this message or not. If we were previously not in recovery and started recovery because we saw a sequence number gap, we call the *startSnapshotSync()* method, which we will see shortly. Just to provide a brief introduction here, the *startSnapshotSync()* method will initialize the *snapshot_mcast_socket_* object and subscribe to the snapshot multicast stream, but more on that later. When in recovery, we call the *queueMessage()* method to store the *MDPMarketUpdate* message we just received. We stay in recovery mode and queue up market data updates on both the snapshot and incremental streams. We will do this until we have a complete snapshot of the book from the snapshot stream and all the incremental messages after the snapshot message to catch up with the incremental stream. We will cover more details on that shortly when we present the actual implementation of the *checkSnapshotSync()* method:

#+begin_src cpp
        if (UNLIKELY(in_recovery_)) {
          if (UNLIKELY(!already_in_recovery)) {
            logger_.log("%:% %() % Packet drops on %
              socket. SeqNum expected:% received:%\n",
                __FILE__, __LINE__, __FUNCTION__,
                        Common::getCurrentTimeStr
                          (&time_str_), (is_snapshot ?
                            "snapshot" : "incremental"),
                              next_exp_inc_seq_num_,
                                 request->seq_num_);
            startSnapshotSync();
          }
          queueMessage(is_snapshot, request);
        }
#+end_src

For the branch where we are not in recovery and the message we received is from the incremental market data stream, we simply update *next_exp_inc_seq_num_*. This a reminder that the *next_exp_inc_seq_num_* variable tracks the next sequence number we expect on the next incremental market data update. We then write the *MEMarketUpdate* message to the *incoming_md_updates_* lock-free queue, which will be consumed by the trading engine component on the other end:

#+begin_src cpp
          else if (!is_snapshot) {
          logger_.log("%:% %() % %\n", __FILE__, __LINE__,
            __FUNCTION__,
                      Common::getCurrentTimeStr
                        (&time_str_), request->toString());
          ++next_exp_inc_seq_num_;
          auto next_write = incoming_md_updates_->
            getNextToWriteTo();
          *next_write = std::move(request->
            me_market_update_);
          incoming_md_updates_->updateWriteIndex();
        }
      }
#+end_src

Finally, we shift the remaining partial data left in the socket's *rcv_buffer_* buffer and update the next valid receive index for the next read:

#+begin_src cpp
      memcpy(socket->rcv_buffer_, socket->rcv_buffer_ + i,
        socket->next_rcv_valid_index_ - i);
      socket->next_rcv_valid_index_ -= i;
    }
  }
#+end_src

That concludes the implementation of the *recvCallback()* method and we will now look at the methods that handle snapshot subscription and synchronization logic. First, we investigate the *startSnapshotSync()* method, which, as we mentioned before, prepares the *MarketDataConsumer* class to start the snapshot synchronization mechanism on sequence number gaps. The first thing we do for this task is clear the two *std::map* containers -- *snapshot_queued_msgs_* and *incremental_queued_msgs_*, which we use to queue upmarket update messages from the snapshot and incremental streams. Then we initialize the *snapshot_mcast_socket_* object using the *McastSocket::init()* method so that the socket gets created for the *snapshot_ip_* and *snapshot_port_* address. Then we call the *McastSocket::join()* method to start the multicast subscription for the snapshot market data stream. Remember that for multicast sockets, we need to make sure that not only do we have a socket that is reading market data, but we also have to issue the IGMP join membership network-level message so that messages can flow to the application, which is achieved by the call to *snapshot_mcast_socket_.join()*:

#+begin_src cpp
  auto MarketDataConsumer::startSnapshotSync() -> void {
    snapshot_queued_msgs_.clear();
    incremental_queued_msgs_.clear();
    ASSERT(snapshot_mcast_socket_.init(snapshot_ip_,
      iface_, snapshot_port_, /*is_listening*/ true) >= 0,
           "Unable to create snapshot mcast socket. error:"
              + std::string(std::strerror(errno)));
    ASSERT(snapshot_mcast_socket_.join(snapshot_ip_,
      iface_, snapshot_port_),
           "Join failed on:" + std::to_string
             (snapshot_mcast_socket_.fd_) + " error:" +
               std::string(std::strerror(errno)));
  }
#+end_src

The next section handles a very important responsibility of the *MarketDataConsumer* component, which is queueing up market data updates from the snapshot and incremental stream and synchronizing when needed.

** Synchronizing with the snapshot stream

The first method we need to implement is the *MarketDataConsumer::queueMessage()* method, which we invoked earlier. This method receives an *MDPMarketUpdate* message and a flag that captures whether it was received from the snapshot stream or the incremental stream.

If the message came over the incremental market data stream, then it adds it to *incremental_queued_msgs_* *std::map*. If it is received over the snapshot stream, then first, it checks to see if a market update for that sequence number already exists in the *snapshot_queued_msgs_* container. If the entry for that sequence number already exists in the container, then that means that we are receiving a new snapshot messages cycle and we were not able to successfully recover from the previous snapshot messages cycle. In this case, it clears the *snapshot_queued_msgs_* container since we will have to restart the snapshot recovery process from the beginning. Finally, the *MEMarketUpdate* message is added to the *snapshot_queued_msgs_* container:

#+begin_src cpp
auto MarketDataConsumer::queueMessage(bool is_snapshot,
                                        const Exchange::
                                          MDPMarketUpdate
                                            *request) {
    if (is_snapshot) {
      if (snapshot_queued_msgs_.find(request->seq_num_) !=
        snapshot_queued_msgs_.end()) {
        logger_.log("%:% %() % Packet drops on snapshot
          socket. Received for a 2nd time:%\n", __FILE__,
            __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_),
                      request->toString());
        snapshot_queued_msgs_.clear();
      }
      snapshot_queued_msgs_[request->seq_num_] = request->
        me_market_update_;
    } else {
      incremental_queued_msgs_[request->seq_num_] =
        request->me_market_update_;
    }
#+end_src

After the new message is queued in the correct container, we call the *checkSnapshotSync()* method to see if we can successfully recover from the snapshot and the incremental messages we have queued up so far:

#+begin_src cpp
    logger_.log("%:% %() % size snapshot:% incremental:% %
      => %\n", __FILE__, __LINE__, __FUNCTION__,
                Common::getCurrentTimeStr(&time_str_),
                  snapshot_queued_msgs_.size(),
                    incremental_queued_msgs_.size(),
                      request->seq_num_, request->
                        toString());
    checkSnapshotSync();
}
#+end_src

Now, we will implement the last and most important method in the *MarketDataConsumer* class -- *checkSnapshotSync()*, which inspects the queued *MEMarketUpdate* messages in the snapshot and incremental containers to see if we can successfully recover or synchronize with the snapshot and incremental streams and /catch up/:

1. The logic is to queue up messages received on the snapshot and incremental market data streams.
2. Then, when we receive *MarketUpdateType::SNAPSHOT_END*, we make sure that no messages were dropped on the snapshot market data stream by checking that there is no gap in the sequence number field on the snapshot messages.
3. Then, we inspect the queued market updates from the incremental data stream and check to see if we have messages following the last message that was used to synthesize this round of snapshot messages. We do this by checking if we have market updates in the incremental queue starting with a sequence number equal to the *OrderId + 1* value from the *SNAPSHOT_END* message in the snapshot queue.
4. Finally, we check to make sure that from that point on in the incremental queued messages, we do not have another gap.

To better understand how the snapshot recovery logic works, we present /Figure 8//.2/, a concrete example of when recovery is possible:

[[file:///Users/toeinriver/Documents/org/web/WebImg/92f4e0c50db8ee7b6a7bfd502c964ae30849e6ff4ea21ca818bdc88b3308a117.jpg]]

Figure 8.2 -- Example state of snapshot and incremental queues when recovery is possible

Applying the logic we just presented in /Figure 8//.2/, we first check the *snapshot_queued_msgs_* container to make sure we have a *SNAPSHOT_START* message and a *SNAPSHOT_END* message. We also make sure that we do not have any gaps in the snapshot messages by checking the sequence numbers, which start from zero and increment by one for each message. We find the last sequence number, which was used to synthesize this snapshot from the *SNAPSHOT_END* message and use the order ID field in that message, which in this case, is set to *776*.

Once we determine that we have a complete sequence of snapshot messages, we check the queue of incremental market data updates. All queued-up incremental messages with a sequence number less than or equal to *776* will be discarded since the snapshot messages incorporate that information. Then we process/apply all the queued-up incremental updates starting with sequence number *777* and making sure that we do not have a gap in the incremental queued-up messages. We achieve that by checking the sequence number field on those messages and making sure there is no gap in it. Once we have processed all the queued-up incremental market data updates, we are done. At this point, we have finished the recovery/synchronization process and are /caught up/. Now that we understand how the logic is supposed to work, let us look at the C++ implementation of the *checkSnapshotSync()* method.

First, we check if the *snapshot_queued_msgs_* container is empty. Obviously, we cannot recover since we need a full snapshot messages cycle and all the incremental messages from that point on to catch up with the incremental stream:

#+begin_src cpp
  auto MarketDataConsumer::checkSnapshotSync() -> void {
    if (snapshot_queued_msgs_.empty()) {
      return;
    }
#+end_src

The next thing we need to check is if we have *MEMarketUpdate* of the *MarketUpdateType::SNAPSHOT_START* type. Otherwise, we clear the queue and wait for the next round of snapshot messages:

#+begin_src cpp
    const auto &first_snapshot_msg =
      snapshot_queued_msgs_.begin()->second;
    if (first_snapshot_msg.type_ != Exchange::
      MarketUpdateType::SNAPSHOT_START) {
      logger_.log("%:% %() % Returning because have not
        seen a SNAPSHOT_START yet.\n",
                  __FILE__, __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_));
      snapshot_queued_msgs_.clear();
      return;
    }
#+end_src

Next, we will iterate through the queued snapshot messages and make sure that there is no gap in the snapshot messages we queued up by checking the sequence numbers. Remember that the key in the *snapshot_queued_msgs_* container is actually the *seq_num_* field from the *MDPMarketUpdate* messages. If we detect a gap in the snapshot messages, we set the *have_complete_snapshot* flag to *false* and exit out of the loop. We collect each message from the snapshot queue into the *final_events* container of type *std::vector* of *MEMarketUpdate* messages, which will be the container of all the events we will process if we successfully recover from this snapshot:

#+begin_src cpp
    std::vector<Exchange::MEMarketUpdate> final_events;
    auto have_complete_snapshot = true;
    size_t next_snapshot_seq = 0;
    for (auto &snapshot_itr: snapshot_queued_msgs_) {
      logger_.log("%:% %() % % => %\n", __FILE__, __LINE__,
        __FUNCTION__,
                  Common::getCurrentTimeStr(&time_str_),
                     snapshot_itr.first,
                       snapshot_itr.second.toString());
      if (snapshot_itr.first != next_snapshot_seq) {
        have_complete_snapshot = false;
        logger_.log("%:% %() % Detected gap in snapshot
          stream expected:% found:% %.\n", __FILE__,
            __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_),
                       next_snapshot_seq,
                          snapshot_itr.first, snapshot_itr.
                             second.toString());
        break;
      }
      if (snapshot_itr.second.type_ !=
         Exchange::MarketUpdateType::SNAPSHOT_START &&
          snapshot_itr.second.type_ !=
            Exchange::MarketUpdateType::SNAPSHOT_END)
        final_events.push_back(snapshot_itr.second);
      ++next_snapshot_seq;
    }
#+end_src

Once we finish the loop, we check the *have_complete_snapshot* flag to see if we found a gap in the snapshot messages or not. If the flag is set to *false*, meaning we found a gap, we clear the *snapshot_queued_msgs_* container and return, since we cannot recover and must wait for the next round of snapshot messages:

#+begin_src cpp
    if (!have_complete_snapshot) {
      logger_.log("%:% %() % Returning because found gaps
        in snapshot stream.\n",
                  __FILE__, __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_));
      snapshot_queued_msgs_.clear();
      return;
    }
#+end_src

Assuming we made it this far, we extract the last message in the queue of snapshot messages and make sure that it is of the *MarketUpdateType::SNAPSHOT_END* type since we will need to use the *order_id_* field in this message to process the incremental queue of messages:

#+begin_src cpp
    const auto &last_snapshot_msg = snapshot_queued_msgs_
      .rbegin()->second;
    if (last_snapshot_msg.type_ != Exchange::
      MarketUpdateType::SNAPSHOT_END) {
      logger_.log("%:% %() % Returning because have not
        seen a SNAPSHOT_END yet.\n",
                  __FILE__, __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_));
      return;
    }
#+end_src

Now, we move on to inspecting the queued incremental messages to see if we can synchronize successfully. We define a *have_complete_incremental* boolean flag, which will represent if we have all the messages from the incremental stream without any gaps. We also set the *next_exp_inc_seq_num_* member variable to be *last_snapshot_msg.order_id_ + 1* from the *SNAPSHOT_END* message:

#+begin_src cpp
    auto have_complete_incremental = true;
    size_t num_incrementals = 0;
    next_exp_inc_seq_num_ = last_snapshot_msg.order_id_ + 1;
#+end_src

Now we iterate through all the messages in our *incremental_queued_msgs_* container. We discard the messages that have sequence numbers less than the *next_exp_inc_seq_num_* variable we just assigned. Otherwise, we make sure that there are no gaps in the queue of incremental messages by making sure that the sequence number on the next message is equal to *next_exp_inc_seq_num_* and setting the *have_complete_incremental* flag to *false* if we detect a gap:

#+begin_src cpp
    for (auto inc_itr = incremental_queued_msgs_.begin();
      inc_itr != incremental_queued_msgs_.end(); ++inc_itr) {
      logger_.log("%:% %() % Checking next_exp:% vs. seq:%
        %.\n", __FILE__, __LINE__, __FUNCTION__,
                  Common::getCurrentTimeStr(&time_str_),
                    next_exp_inc_seq_num_, inc_itr->first,
                      inc_itr->second.toString());
      if (inc_itr->first < next_exp_inc_seq_num_)
        continue;
      if (inc_itr->first != next_exp_inc_seq_num_) {
        logger_.log("%:% %() % Detected gap in incremental
          stream expected:% found:% %.\n", __FILE__,
            __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_),
                      next_exp_inc_seq_num_, inc_itr->
                        first, inc_itr->second.toString());
        have_complete_incremental = false;
        break;
      }
#+end_src

If we do not detect a gap in the market update message from the incremental queue, we add it to the *final_events* container as we did before. We also increment the *next_exp_inc_seq_num_* variable, since that is the next sequence number we expect if there are no gaps:

#+begin_src cpp
      logger_.log("%:% %() % % => %\n", __FILE__, __LINE__,
        __FUNCTION__,
                  Common::getCurrentTimeStr(&time_str_),
                    inc_itr->first, inc_itr->second
                       .toString());
      if (inc_itr->second.type_ != Exchange::
        MarketUpdateType::SNAPSHOT_START &&
          inc_itr->second.type_ != Exchange::
             MarketUpdateType::SNAPSHOT_END)
        final_events.push_back(inc_itr->second);
      ++next_exp_inc_seq_num_;
      ++num_incrementals;
    }
#+end_src

After exiting the loop, we check the *have_complete_incremental* flag to make sure there was no gap in the queue of incremental updates. If we did find a gap, we clear the *snapshot_queued_msgs_* container and return, since we cannot successfully synchronize:

#+begin_src cpp
    if (!have_complete_incremental) {
      logger_.log("%:% %() % Returning because have gaps in
        queued incrementals.\n",
                  __FILE__, __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_));
      snapshot_queued_msgs_.clear();
      return;
    }
#+end_src

At this point, we have successfully recovered, so we iterate through all the *MEMarketUpdate* messages in the *final_events* container and write them to the *incoming_md_updates_* lock-free queue to be sent to the trading engine component:

#+begin_src cpp
    for (const auto &itr: final_events) {
      auto next_write = incoming_md_updates_->
        getNextToWriteTo();
      *next_write = itr;
      incoming_md_updates_->updateWriteIndex();
    }
#+end_src

Finally, we clear the *snapshot_queued_msgs_* container and the *incremental_queued_msgs_* container and set the *in_recovery_* flag to *false* since we are no longer in recovery mode. Finally, we call the *McastSocket::leave()* method on *snapshot_mcast_socket_*, since we no longer need to be subscribed to the snapshot stream or receive or process the snapshot messages:

#+begin_src cpp
    logger_.log("%:% %() % Recovered % snapshot and %
      incremental orders.\n", __FILE__, __LINE__,
         __FUNCTION__,
                Common::getCurrentTimeStr(&time_str_),
                  snapshot_queued_msgs_.size() - 2,
                    num_incrementals);
    snapshot_queued_msgs_.clear();
    incremental_queued_msgs_.clear();
    in_recovery_ = false;
    snapshot_mcast_socket_.leave(snapshot_ip_,
      snapshot_port_);;
  }
#+end_src

With this method, we have concluded the design and implementation of our *MarketDataConsumer* component. Next, we will move on to the topic of constructing the limit order book inside the trading engine from these market data update messages.

* Building order books from market data

In the previous section, we built the market data consumer component, which subscribes to the market data stream, synchronizes between the snapshot and incremental streams, and decodes the market data updates and publishes them to the trading engine component. The trading engine component then needs to process these market data updates and build a limited order book like the one that the matching engine builds, except this is a much more limited version of the matching engine's order book. As a reminder, we discussed this in the chapter /Designing Our Trading Ecosystem/ in the /Designing a framework for low latency C++ trading algorithms/ section. One last thing to note is that we will re-use the design and code of the order book in the matching engine to create the order book in the client's system. We will re-use the source code we built in the chapter /Building the C++ Matching Engine/ in the /Building the order book and matching orders/ section. Now, let us get started with the implementation of the order book, which we will call *MarketOrderBook*, to easily differentiate it from the order book inside the matching engine, which was called *MEOrderBook*.

** Defining the structures for the market order book

First, we will define the structures and types that make up the *MarketOrderBook* data structure. We use an identical design here as we did for the *MEOrderBook* class, and that design is presented in /Figure 8//.3/. We recommend revisiting the design of the order book and the motivation behind the different choices presented in the /Building the C++ Matching Engine/ chapter in the /Designing the exchange order/ /book/ section.

Each order is represented in a *MarketOrder* struct, which is a subset of the *MEOrder* struct we built for the matching engine. We will also have an *OrderHashMap* type, as we did in the matching engine, which will be a hash map from *OrderId* to these *MarketOrder* objects. Orders at the same price are held in a *MarketOrdersAtPrice* struct as we did in the matching engine, which will be a doubly linked list of *MarketOrder* objects. Remember that we need this structure to maintain all the orders with the same price and side attribute and arrange them in FIFO order. We will also build an *OrdersAtPriceHashMap* map, as we did in the matching engine to be a hash map from *Price* to these *MarketOrdersAtPrice* objects. The design is represented in /Figure 8//.3/, which is similar to the diagram we presented for the order book in the matching engine, except with different structures in this case:

[[file:///Users/toeinriver/Documents/org/web/WebImg/90f0adc615ab4fe25ace8ff85cc223d9d05a416d1f256a4aba248927047ab57a.jpg]]

Figure 8.3 -- Architecture of the limit order book in the market participant's trading engine

All the source code for the structures and types we define in the next two sub-sections can be found in the *Chapter8/trading/strategy/market_order.h* source file and the *Chapter8/trading/strategy/market_order.cpp* source file. Let us get started with the *MarketOrderBook* implementation by first defining the data structures and types we will need.

*** Defining the MarketOrder structure and OrderHashMap type

First, we will define the *MarketOrder* structure, which represents a single order in the market data stream. This structure contains the *OrderId*, *Side*, *Price*, *Qty*, and *Priority* attributes. It also contains a *prev_order_* and a *next_order_* member of type *MarketOrder* pointer since we will chain these objects in a doubly linked list:

#+begin_src cpp
#pragma once
#include <array>
#include <sstream>
#include "common/types.h"
using namespace Common;
namespace Trading {
  struct MarketOrder {
    OrderId order_id_ = OrderId_INVALID;
    Side side_ = Side::INVALID;
    Price price_ = Price_INVALID;
    Qty qty_ = Qty_INVALID;
    Priority priority_ = Priority_INVALID;
    MarketOrder *prev_order_ = nullptr;
    MarketOrder *next_order_ = nullptr;
#+end_src

The constructor is straightforward; it simply initializes the fields it is provided in the constructor:

#+begin_src cpp
    // only needed for use with MemPool.
    MarketOrder() = default;
    MarketOrder(OrderId order_id, Side side, Price price,
      Qty qty, Priority priority, MarketOrder *prev_order,
        MarketOrder *next_order) noexcept
        : order_id_(order_id), side_(side), price_(price),
           qty_(qty), priority_(priority),
             prev_order_(prev_order),
               next_order_(next_order) {}
    auto toString() const -> std::string;
  };
#+end_src

We also define the *OrderHashMap* type, which is an *std::array* array of *MarketOrder* pointer objects and of size *ME_MAX_ORDER_IDS* *, in the* same way as we did in the matching engine order book:

#+begin_src cpp
  typedef std::array<MarketOrder *, ME_MAX_ORDER_IDS> OrderHashMap;
#+end_src

The *toString()* method we will use for logging purposes is self-explanatory:

#+begin_src cpp
  auto MarketOrder::toString() const -> std::string {
    std::stringstream ss;
    ss << "MarketOrder" << "["
       << "oid:" << orderIdToString(order_id_) << " "
       << "side:" << sideToString(side_) << " "
       << "price:" << priceToString(price_) << " "
       << "qty:" << qtyToString(qty_) << " "
       << "prio:" << priorityToString(priority_) << " "
       << "prev:" << orderIdToString(prev_order_ ?
           prev_order_->order_id_ : OrderId_INVALID) << " "
       << "next:" << orderIdToString(next_order_ ?
         next_order_->order_id_ : OrderId_INVALID) << "]";
    return ss.str();
  }
#+end_src

Next, we will define the *MarketOrdersAtPrice* structure, which holds a linked list of *MarketOrder* objects.

*** Defining the MarketOrdersAtPrice structure and OrdersAtPriceHashMap type

The *MarketOrdersAtPrice* struct is identical to the *MEOrdersAtPrice* struct we built for the matching *MEOrderBook* engine. It contains *Side*, *Price*, and a *MarketOrder* *first_mkt_order_* pointer to represent the beginning of the *MarketOrder*-linked list at this price. It also contains two *MarketOrdersAtPrice* pointers, *prev_entry_* and *next_entry_*, since we will create a doubly linked list of *MarketOrdersAtPrice* objects to represent the price levels:

#+begin_src cpp
  struct MarketOrdersAtPrice {
    Side side_ = Side::INVALID;
    Price price_ = Price_INVALID;
    MarketOrder *first_mkt_order_ = nullptr;
    MarketOrdersAtPrice *prev_entry_ = nullptr;
    MarketOrdersAtPrice *next_entry_ = nullptr;
#+end_src

The constructors for this class are self-explanatory. It simply initializes the data members with the arguments provided:

#+begin_src cpp
    MarketOrdersAtPrice() = default;
    MarketOrdersAtPrice(Side side, Price price, MarketOrder
      *first_mkt_order, MarketOrdersAtPrice *prev_entry,
         MarketOrdersAtPrice *next_entry)
        : side_(side), price_(price),
          first_mkt_order_(first_mkt_order),
            prev_entry_(prev_entry),
              next_entry_(next_entry) {}
#+end_src

The *toString()* method is identical to the one in the matching engine, so we will skip repeating it here:

#+begin_src cpp
    auto toString() const;
  };
#+end_src

Finally, *OrdersAtPriceHashMap* is identical to the one we built for the matching engine. It represents a hash map from *Price* to *MarketOrdersAtPrice* pointers:

#+begin_src cpp
  typedef std::array<MarketOrdersAtPrice *,
    ME_MAX_PRICE_LEVELS> OrdersAtPriceHashMap;
#+end_src

Now, we can finally implement the *MarketOrderBook* class in the next section, but before that, we need to define one more structure that will be used by various components to build a view of the *Best Bid* *Offer* (*BBO*).

*** Defining the BBO structure

Finally, we need to define another structure that will represent the total quantity available at the best bid and ask prices. This will represent the best (most aggressive) buy and sell prices available in the market as well as the sum of the quantities of all the orders at those prices. This structure, called *BBO,* only has four members -- *bid_price_* and *ask_price_ (*both *Price* types to represent the best prices), and *bid_qty_* and *ask_qty_* to represent the total quantity of all orders at these prices.

The BBO abstraction is used by many different components inside the trade engine. Typically, this is used by components that need a summary of the best market prices and liquidity, instead of the full depth of the book and all the details about each order in the book. For example, a component such as the *RiskManager* component, which only needs to compute the open *Profit and Loss* (*PnL*) for an open position when the top-of-book prices change, does not need access to the full order book and instead can be simplified using a BBO abstraction. Other components, such as *FeatureEngine*, *PositionKeeper*, *LiquidityTaker*, and *MarketMaker*, also use the BBO abstraction where the full order book is not needed.

To make it easy to log such objects, we will also add a *toString()* method:

#+begin_src cpp
  struct BBO {
    Price bid_price_ = Price_INVALID, ask_price_ =
      Price_INVALID;
    Qty bid_qty_ = Qty_INVALID, ask_qty_ = Qty_INVALID;
    auto toString() const {
      std::stringstream ss;
      ss << "BBO{"
         << qtyToString(bid_qty_) << "@" <<
           priceToString(bid_price_)
         << "X"
         << priceToString(ask_price_) << "@" <<
            qtyToString(ask_qty_)
         << "}";
      return ss.str();
    };
  };
#+end_src

Now, we can finally move on to our implementation of the *MarketOrderBook* class.

** Defining the data members in the order book

To build the *MarketOrderBook* class, we first need to define the data members in this class. All the source code for this class can be found in the *Chapter8/trading/strategy/market_order_book.h* source file and the *Chapter8/trading/strategy/market_order_book.cpp* source file.

The important data members in this class are the following:

- A *trade_engine_* variable of the *TradeEngine* pointer type. We have not defined this class yet, but we will in this chapter. For now, it represents the class that is the trading engine framework. We will communicate changes to the order book using this variable.
- Two memory pools, *order_pool_* for *MarketOrder* objects and *orders_at_price_pool_* for *MarketOrdersAtPrice* objects, are to be used to allocate and deallocate these objects as needed. The first pool, *order_pool_*, is used to allocate and deallocate *MarketOrder* objects. The second pool, *orders_at_price_pool_*, is used to allocate and deallocate *MarketOrdersAtPrice* objects. Remember that a single *MemPool* instance is tied to a specific object type provided to it as a template parameter.
- A *bbo_* variable of the *BBO* type, which will be used to compute and maintain a *BBO*-view of the order book when there are updates and provided to any components that require it.
- An *oid_to_order_* variable of the *OrderHashMap* type will be used to track *MarketOrder* objects by *OrderId*.
- A *price_orders_at_price_* variable of the *OrdersAtPriceHashMap* type to track *OrdersAtPrice* objects by *Price*.
- Two pointers to *MarketOrdersAtPrice* -- *bids_by_price_* to represent the doubly linked list of bids sorted by price and *asks_by_price_* to represent the doubly linked list of asks sorted by price.
- Finally, some variables that are not so important, such as *ticker_id_*, *time_str_*, and *logger_* for logging purposes:

#+begin_src cpp
#pragma once
#include "common/types.h"
#include "common/mem_pool.h"
#include "common/logging.h"
#include "market_order.h"
#include "exchange/market_data/market_update.h"
namespace Trading {
  class TradeEngine;
  class MarketOrderBook final {
  private:
    const TickerId ticker_id_;
    TradeEngine *trade_engine_ = nullptr;
    OrderHashMap oid_to_order_;
    MemPool<MarketOrdersAtPrice> orders_at_price_pool_;
    MarketOrdersAtPrice *bids_by_price_ = nullptr;
    MarketOrdersAtPrice *asks_by_price_ = nullptr;
    OrdersAtPriceHashMap price_orders_at_price_;
    MemPool<MarketOrder> order_pool_;
    BBO bbo_;
    std::string time_str_;
    Logger *logger_ = nullptr;
  };
#+end_src

We will also define a *MarketOrderBookHashMap* type, which is just a hash map from *TickerId* to *MarketOrderBook* objects of the *ME_MAX_TICKERS* size. This constant, as well as the others we will encounter in the next code snippet, were defined in the /Building the C++ Matching Engine/ chapter in the /Defining the operations and interactions in our matching engine/ section, within the /Defining some types and/ /constants/ sub-section:

#+begin_src cpp
  typedef std::array<MarketOrderBook *, ME_MAX_TICKERS>
    MarketOrderBookHashMap;
}
#+end_src

Next, we will see how to initialize the *MarketOrderBook* class and its member variables.

** Initializing the order book

In this sub-section, we will implement the code to initialize the *MarketOrderBook* class as well as its internal data members. The constructor is straightforward and accepts the *TickerId* and *Logger* instances it will use to log. It initializes *orders_at_price_pool_* of *MarketOrdersAtPrice* objects to be of the *ME_MAX_PRICE_LEVELS* size and *order_pool_* of the *MarketOrder* objects to be of the *ME_MAX_ORDER_IDS* size:

#+begin_src cpp
#include "market_order_book.h"
#include "trade_engine.h"
namespace Trading {
  MarketOrderBook::MarketOrderBook(TickerId ticker_id,
    Logger *logger)
      : ticker_id_(ticker_id),
        orders_at_price_pool_(ME_MAX_PRICE_LEVELS),
          order_pool_(ME_MAX_ORDER_IDS), logger_(logger) {
  }
#+end_src

The destructor for this class just resets the internal data members:

#+begin_src cpp
  MarketOrderBook::~MarketOrderBook() {
    logger_->log("%:% %() % OrderBook\n%\n", __FILE__,
      __LINE__, __FUNCTION__,
                 Common::getCurrentTimeStr(&time_str_),
                   toString(false, true));
    trade_engine_ = nullptr;
    bids_by_price_ = asks_by_price_ = nullptr;
    oid_to_order_.fill(nullptr);
  }
#+end_src

There is an additional utility method called *setTradeEngine()*, which is a better method to set the *trade_engine_* variable with an instance of a *TradeEngine* object:

#+begin_src cpp
    auto setTradeEngine(TradeEngine *trade_engine) {
      trade_engine_ = trade_engine;
    }
#+end_src

Now that we have seen how to initialize our *MarketOrderBook* class, we will discuss the most important functionality for this class, which is updating the order book from *MEMarketUpdate* messages that it will receive from the *TradeEngine* engine.

** Processing market updates and updating the order book

The *onMarketUpdate()* method is called along with the *MEMarketUpdate* message that needs to be processed. This method updates the order book from the market update, which is passed as an argument. We will understand the source code to handle these messages, but we will go code block by code block for each case of *MarketUpdateType*.

Before we get into the handling of the actual messages, we will first initialize a *bid_updated* boolean flag and an *ask_updated* boolean flag, which will represent if *BBO* will need to be updated because of this market update. We figure that out by checking if the market update we received corresponds to *side_ == Side::BUY* and *price_* of *market_update* is equal to or greater than *price_* of the current best bid, which we fetch from the *bids_by_price_->price_* variable. We do the same thing for the ask side by checking for *Side::SELL* on *market_update_->side_* and checking if *price_* of *market_update* is less than or equal to the price of the best ask (*asks_by_price_->price_*):

#+begin_src cpp
  auto MarketOrderBook::onMarketUpdate(const
    Exchange::MEMarketUpdate *market_update) noexcept -> void {
    const auto bid_updated = (bids_by_price_ &&
      market_update->side_ == Side::BUY && market_update->
        price_ >= bids_by_price_->price_);
    const auto ask_updated = (asks_by_price_ &&
      market_update->side_ == Side::SELL && market_update->
         price_ <= asks_by_price_->price_);
#+end_src

First, we see the handling for *MarketUpdateType::ADD*. We will allocate a new *MarketOrder* object and call the *addOrder()* method on it. This *addOrder()* method is identical to the *addOrder()* method we built for the matching engine except it operates on *MarketOrder* and *MarketOrdersAtPrice* objects. We will discuss this *addOrder()* method briefly in the next sub-section, but we will not be fully re-implementing it since we have seen all the details in the /Building the C++ Matching/ /Engine/ chapter:

#+begin_src cpp
    switch (market_update->type_) {
      case Exchange::MarketUpdateType::ADD: {
        auto order = order_pool_.allocate(market_update->
          order_id_, market_update->side_, market_update->
            price_,
            market_update->qty_, market_update->priority_,
             nullptr, nullptr);
        addOrder(order);
      }
        break;
#+end_src

The handling for the *MarketUpdateType::MODIFY* case finds the *MarketOrder* structure for which the modified message is targeted. It then updates the *qty_* attribute on that order:

#+begin_src cpp
      case Exchange::MarketUpdateType::MODIFY: {
        auto order = oid_to_order_.at(market_update->
          order_id_);
        order->qty_ = market_update->qty_;
      }
        break;
#+end_src

The handling for *MarketUpdateType::CANCEL* is straightforward, and it finds *MarketOrder*, for which the cancel message is, and then calls the *removeOrder()* method on it. The *removeOrder()* method is also identical to the *removeOrder()* method we built for the matching engine order book in the /Building the C++ Matching Engine/ chapter, except it operates on *MarketOrder* and *MarketOrdersAtPrice* objects. Again, we will not fully re-implement these methods since they are identical to what we have seen, and the details can be found in that chapter and the source files:

#+begin_src cpp
      case Exchange::MarketUpdateType::CANCEL: {
        auto order = oid_to_order_.at(market_update->
          order_id_);
        removeOrder(order);
      }
        break;
#+end_src

The *MarketUpdateType::TRADE* messages do not change the order book, so here, we simply forward that trade message back to the *TradeEngine* engine using the *onTradeUpdate()* method. One thing to note here is that in the case of *MarketUpdateType::TRADE*, we simply return after calling the *TradeEngine::onTradeUpdate()* method. This is because the trade messages do not update the order book in our market data protocol, so the subsequent code after this *switch case* does not need to be executed:

#+begin_src cpp
      case Exchange::MarketUpdateType::TRADE: {
        trade_engine_->onTradeUpdate(market_update, this);
        return;
      }
        break;
#+end_src

The *MarketOrderBook* class needs to handle the *MarketUpdateType::CLEAR* messages. It receives these messages when the book needs to be cleared because we dropped a packet and are recovering from the snapshot stream. All it does here is deallocate all the valid *MarketOrder* objects in the book and clear the *oid_to_order_* container by setting each entry to *nullptr*. It then iterates through the double-linked list starting with the *bids_by_price_* pointer and deallocates each *MarketOrdersAtPrice* object back to the *orders_at_price_pool_* memory pool. It does the same thing with the *asks_by_price_* linked list and, finally, sets both *bids_by_price_* and *asks_by_price_* to be *nullptr* to represent an empty book:

#+begin_src cpp
      case Exchange::MarketUpdateType::CLEAR: {
        for (auto &order: oid_to_order_) {
          if (order)
            order_pool_.deallocate(order);
        }
        oid_to_order_.fill(nullptr);
        if(bids_by_price_) {
          for(auto bid = bids_by_price_->next_entry_; bid
            != bids_by_price_; bid = bid->next_entry_)
            orders_at_price_pool_.deallocate(bid);
          orders_at_price_pool_.deallocate(bids_by_price_);
        }
        if(asks_by_price_) {
          for(auto ask = asks_by_price_->next_entry_; ask
            != asks_by_price_; ask = ask->next_entry_)
            orders_at_price_pool_.deallocate(ask);
          orders_at_price_pool_.deallocate(asks_by_price_);
        }
        bids_by_price_ = asks_by_price_ = nullptr;
      }
        break;
#+end_src

The *MarketOrderBook* class does not need to handle *INVALID*, *SNAPSHOT_START*, and *SNAPSHOT_END* *MarketUpdateType*s, so it does nothing with those messages:

#+begin_src cpp
      case Exchange::MarketUpdateType::INVALID:
      case Exchange::MarketUpdateType::SNAPSHOT_START:
      case Exchange::MarketUpdateType::SNAPSHOT_END:
        break;
    }
#+end_src

At this point, we will call the *updateBBO()* method and pass it to the two boolean flags we computed: *bid_updated* and *ask_updated*. We will look at the implementation of this method shortly, but for now, you should understand that it will use the two boolean flags passed to it to decide if it needs to update the bid side or the ask side *BBO* values:

#+begin_src cpp
    updateBBO(bid_updated, ask_updated);
#+end_src

Finally, it notifies the *TradeEngine* engine that the order book was updated using the *onOrderBookUpdate()* method, which we will discuss later in this chapter and enrich further in the next chapter:

#+begin_src cpp
    trade_engine_->onOrderBookUpdate(market_update->
      ticker_id_, market_update->price_, market_update->
        side_);
    logger_->log("%:% %() % OrderBook\n%\n", __FILE__,
      __LINE__, __FUNCTION__,
                 Common::getCurrentTimeStr(&time_str_),
                   toString(false, true));
  }
#+end_src

Before we conclude this section, let us look at the implementation of the *updateBBO()* method we referred to before. The implementation itself is relatively straightforward, so let us look at the handling for the bid side first. Once we understand how we handle the bid side, understanding the ask side will be very simple since it is exactly the same. The first thing we do is check if the *update_bid* parameter passed to it is *true*. Only then do we have to update the bid side of the *BBO* object. Next, we check if the *bids_by_price_* member is not *nullptr*. If it is not valid, then we set the *bid_price_* variable and the *bid_qty_* variable to be invalid (*Price_INVALID* and *Qty_INVALID* respectively) since the side is empty. The more interesting handling is in the case where the *bids_by_price_* member is valid.

In that case, we set the bid_*price_* member variable in the *bbo_* object to be the price of the best bid: *bids_by_price_->price_*. To compute *bid_qty_* in the *bbo_* object, we first assign it *qty_* of the first order at that price level, which we access using the *bids_by_price_->first_mkt_order_->qty_* value. Then, we linearly iterate over all the orders at that price level by following the *next_order_* pointers until we wrap around, i.e. the *next_order_* points to the *first_mkt_order_* object. For each order we iterate over, we accumulate the *qty_* value of that order into the *bid_qty_* member in our *bbo_* object. At this point, we are done updating the bid side of the *BBO* object. Note here that the linear iteration is slightly inefficient and can be improved for example by tracking and updating these values during the processing of the *MEMarketUpdate* messages itself, but we leave that (simple) exercise up to the interested reader:

#+begin_src cpp
    auto updateBBO(bool update_bid, bool update_ask)
      noexcept {
      if(update_bid) {
        if(bids_by_price_) {
          bbo_.bid_price_ = bids_by_price_->price_;
          bbo_.bid_qty_ = bids_by_price_->first_mkt_order_-
            >qty_;
          for(auto order = bids_by_price_->
            first_mkt_order_->next_order_; order !=
              bids_by_price_->first_mkt_order_; order =
                order->next_order_)
            bbo_.bid_qty_ += order->qty_;
        }
        else {
          bbo_.bid_price_ = Price_INVALID;
          bbo_.bid_qty_ = Qty_INVALID;
        }
      }
#+end_src

The handling for the ask side of the *BBO* is identical to the handling for the bid side we just discussed. We will not repeat ourselves, but here is that handling:

#+begin_src cpp
      if(update_ask) {
        if(asks_by_price_) {
          bbo_.ask_price_ = asks_by_price_->price_;
          bbo_.ask_qty_ = asks_by_price_->first_mkt_order_-
            >qty_;
          for(auto order = asks_by_price_->
            first_mkt_order_->next_order_; order !=
              asks_by_price_->first_mkt_order_; order =
                order->next_order_)
            bbo_.ask_qty_ += order->qty_;
        }
        else {
          bbo_.ask_price_ = Price_INVALID;
          bbo_.ask_qty_ = Qty_INVALID;
        }
      }
    }
#+end_src

That concludes most of the functionality we need in our *MarketOrderBook* class. In the next sub-section, we will quickly recap a couple of the utility methods we built for the order book in the matching engine, and we will replicate them for the trading engine's order book.

** Revisiting the generic utility methods for order book management

In the /Building the C++ Matching Engine/ chapter, we built *MEOrderBook* in the matching engine in the /Building the order book and matching/ /orders/ section.

We explained and implemented the *priceToIndex()* method and the *getOrdersAtPrice()* method in the /Building the internal data structures/ sub-section. We have identical methods in our *MarketOrderBook* class, except they operate on *MarketOrdersAtPrice* instead of *MEOrdersAtPrice*. We will not discuss them again or re-implement them here, but we provide the signatures for those two methods:

#+begin_src cpp
    auto priceToIndex(Price price) const noexcept;
    auto getOrdersAtPrice(Price price) const noexcept ->
      MarketOrdersAtPrice;
#+end_src

In the /Handling new passive orders/ sub-section in that chapter, we explained the logic and implemented the methods *addOrder()* and *addOrdersAtPrice()*. Again, for the *MarketOrderBook* class, the logic is identical except it operates on *MarketOrder* instead of the *MEOrder* structure and *MarketOrdersAtPrice* objects instead of *MEOrdersAtPrice* objects. The signatures for those two methods in the *MarketOrderBook* class are presented here, but we will skip repeating the explanation and source code here since it is identical:

#+begin_src cpp
    auto addOrder(MarketOrder *order) noexcept -> void;
    auto addOrdersAtPrice(MarketOrdersAtPrice
      *new_orders_at_price) noexcept;
#+end_src

Similarly, in the /Handling order cancellation requests/ sub-section, we covered the details behind the *removeOrder()* and *removeOrdersAtPrice()* methods. Again, for our *MarketOrderBook* class, these methods work exactly the same except they operate on the *MarketOrder* and *MarketOrdersAtPrice* structures:

#+begin_src cpp
    Auto removeOrdersAtPrice(Side side, Price price)
      noexcept;
    auto removeOrder(MarketOrder *order) noexcept -> void;
#+end_src

This concludes the design and implementation of the order book inside the trading engine framework. Next, we need to discuss the order gateway infrastructure component, which is what the *TradeEngine* component will use to communicate with the electronic trading exchange.

* Connecting to the exchange and sending and receiving order flow

The order gateway client component in the market participant's trading infrastructure receives order requests from the trading engine through a lock-free queue and sends order responses back to the trading engine through another lock-free queue. It also establishes a TCP connection to the order gateway server in the exchange side infrastructure. It encodes order requests in the exchange's order format and sends them over the TCP connection. It also consumes order responses sent by the exchange over that TCP connection and decodes them from the order data format. We present the order gateway client diagram again to refresh your memory on that component's design.

[[file:///Users/toeinriver/Documents/org/web/WebImg/aa88f4af4f7f4fa649d65ef530923c7b2afd34df33f22d0a9993ee577cceff3f.jpg]]

Figure 8.4 -- Diagram presenting the order gateway client component inside the client's trading infrastructure

We will start the implementation of this order gateway client component by defining the internal data members of that class first. All the source code for the order gateway client component is in the *Chapter8/trading/order_gw/order_gateway.h* source file and the *Chapter8/trading/order_gw/order_gateway.cpp* source files.

** Defining the data members in the order gateway client

The important data members in the *OrderGateway* class are described here:

- Two lock-free queue pointers. The first one is named *outgoing_requests_* of the *ClientRequestLFQueue* type, which we defined before as an *LFQueue* instance of *MEClientRequest* structures. The other member is called *incoming_responses_*, which is of the *ClientResponseLFQueue* type, which we also defined earlier as an *LFQueue* instance of the *MEClientResponse* structures. These will be used by *OrderGateway* to receive order requests and send order responses to *TradeEngine*.
- It also contains a *tcp_socket_* member variable of the *TCPSocket* type, which is the TCP socket client to be used to connect to the exchange order gateway server and to send and receive messages.
- Two *size_t* variables to represent sequence numbers. The first one, *next_outgoing_seq_num_*, tracks the sequence number that will be sent on the next outgoing *OMClientRequest* message sent to the exchange. The second one, *next_exp_seq_num_*, is used to check and validate that the *OMClientResponse* messages received from the exchange are in sequence.
- A boolean *run_* flag, which serves a similar purpose as it did in all the other components we saw before. It will be used to start and stop the execution of the *OrderGateway* thread and is marked *volatile* since it is accessed from different threads.
- It also saves the network interface in the *iface_* variable and the IP and port of the exchange's order gateway server in the *ip_* and *port_* member variables.
- Finally, it stores the *client_id_* variable of the *ClientId* type to make sure that responses received on the TCP socket are meant for the correct client:

#+begin_src cpp
#pragma once
#include <functional>
#include "common/thread_utils.h"
#include "common/macros.h"
#include "common/tcp_server.h"
#include "exchange/order_server/client_request.h"
#include "exchange/order_server/client_response.h"
namespace Trading {
  class OrderGateway {
  private:
    const ClientId client_id_;
    std::string ip_;
    const std::string iface_;
    const int port_ = 0;
    Exchange::ClientRequestLFQueue *outgoing_requests_ =
      nullptr;
    Exchange::ClientResponseLFQueue *incoming_responses_ =
      nullptr;
    volatile bool run_ = false;
    std::string time_str_;
    Logger logger_;
    size_t next_outgoing_seq_num_ = 1;
    size_t next_exp_seq_num_ = 1;
    Common::TCPSocket tcp_socket_;
  };
}
#+end_src

In the next section, we will initialize these data members as well as the *OrderGateway* class itself.

** Initializing the order gateway client

The constructor accepts the *client_id* ID of the trading client, a pointer to a *ClientRequestsLFQueue* object (*client_requests*), a pointer to a *ClientResponseLFQueue* object (*client_responses*), and the *ip*, *port*, and interface information (*iface*) for the TCP connection. It initializes its own internal variables with these arguments and initializes the *Logger* data member (*logger_*) with a filename for the order gateway logs for this client. It updates the *recv_callback_* member inside the *tcp_socket_* variable of the *TCPSocket* type so that callbacks dispatched on data reads will go to the *OrderGateway::recvCallback()* method. We will see the implementation of that method briefly:

#+begin_src cpp
#include "order_gateway.h"
namespace Trading {
  OrderGateway::OrderGateway(ClientId client_id,
     Exchange::ClientRequestLFQueue *client_requests,
Exchange::ClientResponseLFQueue *client_responses,
  std::string ip, const std::string &iface, int port)
      : client_id_(client_id), ip_(ip), iface_(iface),
        port_(port), outgoing_requests_(client_requests),
          incoming_responses_(client_responses),
      logger_("trading_order_gateway_" + std::
        to_string(client_id) + ".log"),
          tcp_socket_(logger_) {
    tcp_socket_.recv_callback_ = [this](auto socket, auto
      rx_time) { recvCallback(socket, rx_time); };
  }
#+end_src

Like the design of our other components, we will add a *start()* method, which will enable the *run_* flag and create and launch a thread to execute the *run()* method. We will also initialize our *tcp_socket_* member variable and have it connect to the *ip_* and *port_* interface information of the order gateway server at the exchange:

#+begin_src cpp
    auto start() {
      run_ = true;
      ASSERT(tcp_socket_.connect(ip_, iface_, port_, false)
        >= 0,
             "Unable to connect to ip:" + ip_ + " port:" +
               std::to_string(port_) + " on iface:" +
                 iface_ + " error:" +
                   std::string(std::strerror(errno)));
      ASSERT(Common::createAndStartThread(-1,
        "Trading/OrderGateway", [this]() { run(); }) !=
           nullptr, "Failed to start OrderGateway
             thread.");
    }
#+end_src

The destructor for the *OrderGateway* class calls the *stop()* method to stop the execution of the *run()* method and waits for a little bit before returning:

#+begin_src cpp
    ~OrderGateway() {
      stop();
      using namespace std::literals::chrono_literals;
      std::this_thread::sleep_for(5s);
    }
#+end_src

The *stop()* method simply sets the *run_* flag to be *false* to stop the execution of the *run()* loop:

#+begin_src cpp
    auto stop() -> void {
      run_ = false;
    }
#+end_src

Now we can move on to the two remaining important tasks: sending order requests to the exchange and receiving order responses from the exchange.

** Sending order requests to the exchange

In this sub-section, we will implement the *run()* method, which is the main loop for the *OrderGateway* class. The goal of this method is to send out any client requests that are ready to be sent out on the TCP socket to read any data available on the socket and dispatch the *recv_callback_()* method.

First, it calls the *TCPSocket::sendAndRecv()* method to send and receive data on the established TCP connection:

#+begin_src cpp
  auto OrderGateway::run() noexcept -> void {
    logger_.log("%:% %() %\n", __FILE__, __LINE__,
      __FUNCTION__, Common::getCurrentTimeStr(&time_str_));
    while (run_) {
      tcp_socket_.sendAndRecv();
#+end_src

It also reads any *MEClientRequest* messages available on the *outgoing_requests_* *LFQueue* sent by the *TradeEngine* engine and writes them to the *tcp_socket_* send buffer using the *TCPSocket::send()* method. Note that it needs to write out *OMClientRequest* messages, which it achieves by first writing the *next_outgoing_seq_num_* field and then the *MEClientRequest* object that the *TradeEngine* sent. This works because we designed the *OMClientRequest* object to be a struct that contains a *size_t seq_num_* field followed by a *MEClientRequest* object. We also increment the *next_outgoing_seq_num_* instance for the next outgoing socket message:

#+begin_src cpp
      for(auto client_request = outgoing_requests_->
        getNextToRead(); client_request; client_request =
          outgoing_requests_->getNextToRead()) {
        logger_.log("%:% %() % Sending cid:% seq:% %\n",
          __FILE__, __LINE__, __FUNCTION__,
                    Common::getCurrentTimeStr(&time_str_),
                      client_id_, next_outgoing_seq_num_,
                        client_request->toString());
        tcp_socket_.send(&next_outgoing_seq_num_,
          sizeof(next_outgoing_seq_num_));
        tcp_socket_.send(client_request,
          sizeof(Exchange::MEClientRequest));
        outgoing_requests_->updateReadIndex();
        next_outgoing_seq_num_++;
      }
    }
  }
#+end_src

We will deal with the task of receiving and processing order responses that the exchange sends to the TCP connection *OrderGateway* establishes.

** Processing order responses from the exchange

The *recvCallback()* method is called when there is data available on the *tcp_socket_* and the *TCPSocket::sendAndRecv()* method is called from the *run()* method in the previous section. We go through the *rcv_buffer_* buffer on *TCPSocket* and re-interpret the data as *OMClientResponse* messages:

#+begin_src cpp
  auto OrderGateway::recvCallback(TCPSocket *socket, Nanos
    rx_time) noexcept -> void {
    logger_.log("%:% %() % Received socket:% len:% %\n",
      __FILE__, __LINE__, __FUNCTION__,
        Common::getCurrentTimeStr(&time_str_), socket->fd_,
          socket->next_rcv_valid_index_, rx_time);
    if (socket->next_rcv_valid_index_ >=
      sizeof(Exchange::OMClientResponse)) {
      size_t i = 0;
      for (; i + sizeof(Exchange::OMClientResponse) <=
        socket->next_rcv_valid_index_; i +=
          sizeof(Exchange::OMClientResponse)) {
        auto response = reinterpret_cast<const
          Exchange::OMClientResponse *>(socket->rcv_buffer_
            + i);
        logger_.log("%:% %() % Received %\n", __FILE__,
          __LINE__, __FUNCTION__,
           Common::getCurrentTimeStr(&time_str_), response-
             >toString());
#+end_src

For the *OMClientResponse* message we just read into the response variable, we check to make sure the client ID on the response matches the *OrderGateway*'s client ID and ignore the response if it does not match:

#+begin_src cpp
        if(response->me_client_response_.client_id_ !=
          client_id_) {
          logger_.log("%:% %() % ERROR Incorrect client id.
            ClientId expected:% received:%.\n", __FILE__,
               __LINE__, __FUNCTION__,
                      Common::getCurrentTimeStr(&time_str_)
                       , client_id_, response->
                          me_client_response_.client_id_);
          continue;
        }
#+end_src

We also check to make sure that the sequence number on *OMClientResponse* matches what we expect it to be. If there is a mismatch, we log an error and ignore the response. There is an opportunity to improve the error handling here, but for the sake of simplicity, we just log an error and continue:

#+begin_src cpp
        if(response->seq_num_ != next_exp_seq_num_) {
          logger_.log("%:% %() % ERROR Incorrect sequence
            number. ClientId:%. SeqNum expected:%
              received:%.\n", __FILE__, __LINE__,
                __FUNCTION__,
                      Common::getCurrentTimeStr(&time_str_)
                        , client_id_, next_exp_seq_num_,
                           response->seq_num_);
          continue;
        }
#+end_src

Finally, we increment the expected sequence number on the next *OMClientResponse* and write the response we just read to the *incoming_responses_* *LFQueue* for the *TradeEngine* to read. It also updates the *rcv_buffer_* buffer and the next receive index into the *TCPSocket* buffer we just consumed some messages from:

#+begin_src cpp
        ++next_exp_seq_num_;
        auto next_write = incoming_responses_->
          getNextToWriteTo();
        *next_write = std::move(response->
          me_client_response_);
        incoming_responses_->updateWriteIndex();
      }
      memcpy(socket->rcv_buffer_, socket->rcv_buffer_ + i,
        socket->next_rcv_valid_index_ - i);
      socket->next_rcv_valid_index_ -= i;
    }
  }
#+end_src

With this method implementation, we have finished the design and implementation of the *OrderGateway* component. That will be all the core infrastructure components we build in this chapter, and we will summarize everything we worked on in the next chapter.

One important note is that we will need to build all the components presented in this chapter as well as the /Building the C++ Trading Algorithm Building Blocks/ and /Building the C++ Market Making and Liquidity Taking Algorithms/ chapters before we can build and run a meaningful trading client. Since our ecosystem consists of a server (trading exchange) and client (trading client) infrastructure, we will need to wait until the /Building and running the main trading application/ section in the /Building the C++ Market Making and Liquidity Taking Algorithms/ chapter before we can run the full ecosystem.

* Summary

This chapter was dedicated to building the important core infrastructure components inside the market participant's trading system. First, we build the market data consumer component, which is responsible for subscribing to the multicast market data stream generated by the exchange. It needs to detect gaps in market data updates on the incremental market data stream and initiate snapshot recovery and synchronization mechanisms to re-synchronize with the incremental market data stream. It decodes the market data updates from the format that the exchange publishes to a simpler internal market data format.

The order book sub-component inside the trading engine component processes the market data updates it receives from the market data consumer. It builds and updates an order book data structure from these updates for the trading engine to get an accurate view of the market.

The order gateway component inside the trading system establishes and maintains a bi-directional TCP connection with the electronic trading exchange. It receives order action requests from the trading engine and sends them out to the exchange in the exchange's order data format. It also receives order responses that the exchange sends to the trading client, decodes them, and forwards them to the trading engine.

Note that we do not have everything we need in the trading client's trading system, that is, we are missing the components we need to build and run trading strategies and associated components. The next chapter will build the additional components we need in the trading strategy framework. The chapter after that will tie all the components together and finish the final trading application and the full trading ecosystem.

--------------

https://learning.oreilly.com/library/view/building-low-latency/9781837639359/B19434_08.xhtml#_idParaDest-195
